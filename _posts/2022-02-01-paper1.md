---
title: "논문 리뷰1"

categories:
  - Paper
tags:
  - [paper, deeplearning]

toc: true
toc_sticky: true
---

### 1. Title

현대 Neural Networks에서의 Calibration 에 대해 얘기함.

### 2. Abtract

Confidence calibration은 분류 모델에서 중요하다.
depth, width, weight decay, BN등 다양한 요인들이 calibration에 영향을 미친다.
다양한 calibration 방법중 temperature scaling이 좋은 결과를 보여주었다.

### 3.Figures

### 4.Introduction & Conclusion

- **Introduction**
실제상황에서 분류 네트워크는 정확성 뿐만 아니라 정확하지 않을 가능성에 대해서도 알려주어야 한다. 네트워크는 prediction 값 외에 calibrated confidence를 제공해야한다.
현대 신경망은 10년 전 보다 정확하지만 놀랍게도 well-calibrated 되지 않았다 (Figure1).
본 논문은 왜 뉴럴 네트워크들이 miscalibrated 되는지 이해하고, 해결방안을 제시하는 것이 목적이다.
Platt scaling(temperature scaling)은 calibrated probabilities를 구하는데 효과적이며 기존의 딥러닝 프레임워크에서 구현하기 쉬운방법!
- **Conclusion**
현대 신경망은 이상한 현상이 있다. classification error은 감소했지만 probabilistic error&miscalibration은 악화되었다. 모델의 용량, 표준화, 정규화 등은 network calibration에 강한 영향을 미쳤다. 왜 이러한 현상이(*정확도는 증가하지만 calibration에 안좋은 영향이 있는것*) 일어나는지 밝혀내는것은 future work(**ㅋㅋ**)이다.
아무튼 Temperature scaling이라는 간단하고 빠르고 쉬운 효과적인 방법을 입증했다.

### 5. 내용정리

Figure3에서 볼수 있듯이 epoch를 진행하며 모델이 error에 대해서는 과적합이 되지 않지만
NLL에 관해 과적합이 되는것을 볼 수 있다. 이러한 과적합 문제를 해결하기 위해 Temperature scaling을 validation set에서 softmax output에 스케일링을 적용해 NLL의 값을 감소시키는것.